---
title: "final"
author: "Tom"
date: "2023-04-01"
output: html_document
---

# Using machine learning technique to analysis Titanic database

## 1. Introduction

The Titanic disaster is one of the most catastrophic maritime incidents in history. On her maiden voyage, the supposedly "unsinkable" RMS Titanic collided with an iceberg on April 15, 1912, resulting in the death of 1502 out of 2224 passengers and crew due to insufficient lifeboats.

However, it is evident that certain groups of individuals had a higher chance of surviving than others, irrespective of luck. As a result, we have embarked on a machine learning project that aims to answer the question of which types of passengers were more likely to survive. This will be achieved by analyzing a range of passenger data, including their names, ages, genders, socio-economic classes, and other relevant factors.

The rest of the essay will be arranged in following manner: Then we will use the prior belief to conduct feature engineerig.We will then do some exploratory data analysis to examine some prior belief we have on the correlation between features and the target variable(Survived) . Lastly, we will formulate our model with non-parametric and parametric models to analysis the data.

### 1.1 The database

```{r}
# Load packages
library(readr)
library(ggplot2) # visualization
library(dplyr) # data manipulation
library(randomForest) # classification algorithm
library(mice) # imputation
library(caret)
library(Amelia) # Missing Data: Missings Map
library(ROCR) # Prediction: ROC Curve
library(class)
```

```{r message=FALSE, warning=FALSE, paged.print=FALSE}
complete_df<-read_csv("train.csv")
#test_df<-read_csv("test.csv")
#complete_df<- bind_rows(train_df, test_df) # bind training & test data
```

```{r}
summary(complete_df)
```

There are 1309 observations including 12 features in total in our sample. The detailed explanation for each variable is:

| Variable Name | Description                       |
|---------------|-----------------------------------|
| Survived      | Survived (1) or died (0)          |
| Pclass        | Passenger's class                 |
| Name          | Passenger's name                  |
| Sex           | Passenger's sex                   |
| Age           | Passenger's age                   |
| SibSp         | Number of siblings/spouses aboard |
| Parch         | Number of parents/children aboard |
| Ticket        | Ticket number                     |
| Fare          | Fare                              |
| Cabin         | Cabin                             |
| Embarked      | Port of embarkation               |

## 2. data prepossessing

Here we have several prior belief:

1.  There might be negative correlation between survive and age

2.  there can have positive relationship between survive and family size as family members are more likely to help each other

3.  Men are more likely to survive as they are physically stronger

4.  People in different class will have different chance for survive

### 2.1 Feature engeneering

```{r}
rare_title <- c('Dona', 'Lady', 'the Countess','Capt', 'Col', 'Don', 
                'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer')
complete_df<-complete_df|>
  mutate(Title=gsub('(.*, )|(\\..*)', '',Name))|># get title from name.
  #change some non-standard or rare title
  mutate(Title=case_when(Title %in% c("Mlle","MS")~"Miss",
                         Title=="Mme"~"Mrs",
                         Title %in% rare_title ~ "RareTitle",
                         T~Title))|>
  mutate(Surname=sapply(Name,  function(x) strsplit(x, split = '[,.]')[[1]][1]))|>#create the feature of surname
  mutate(SizeFamily=SibSp+Parch+1)|>#family size continuous
  mutate(ScaleFamily=case_when(SizeFamily==1~"Single",
                               SizeFamily>1&SizeFamily<5~"small",
                               SizeFamily>4~"large"))|>#family size discrete
  mutate(Family=paste(Surname,SizeFamily,sep="_"))

```

```{r}
#
plot(factor(Survived) ~ as.factor(ScaleFamily), data=complete_df)
```

### 2.2 Missings

```{r}
missmap(complete_df, main="Titanic Data - Missings Map",
        col=c("yellow", "black"), legend=FALSE)
```

for missing value in embark, there are two missing values, so that we will replace them with the mode

```{r}
complete_df<-complete_df|>
  mutate(Embarked=case_when(is.na(Embarked)~"C",
                            T~Embarked))
```

For missing value in age, as there are , we use a predictive imputation in dealing with it

```{r}
# Make variables factors into factors
factor_vars <- c('PassengerId','Pclass','Sex','Embarked',
                 'Title','Surname','ScaleFamily')
complete_df[factor_vars] <- lapply(complete_df[factor_vars], function(x) as.factor(x))
# Set a random seed
set.seed(123)
# Perform mice imputation, excluding certain less-than-useful variables:
mdl <- mice(complete_df[, !names(complete_df) %in% c('PassengerId','Name','Ticket','Cabin','Survived',"Family")], method='rf') 
```

```{r}
# Save the complete output 
age_mice <- complete(mdl)
par(mfrow=c(1,2))
hist(complete_df$Age, freq=F, main='Original Data', 
  col='blue', ylim=c(0,0.04))
hist(age_mice$Age, freq=F, main='Output', 
  col='lightblue', ylim=c(0,0.04))
```

```{r}
complete_df$Age<-age_mice$Age
```

### 2.3 Feature engineering on age

here we have some prior belief that there is correlation between age and gender on survival rate, let's firstly plot it out for checking

```{r}
complete_df<-complete_df|>
  mutate(Child=case_when(Age<18~1,
                         Age>17~0))|>
  mutate(Mother=case_when(Sex=="female"&Parch>0&Age>18&Title!="Miss"~1,
                          T~0))
```

### 2.3 Exploratory Data Analysis

```{r}
ggplot(complete_df, aes(x = SizeFamily, fill = factor(Survived))) +
  geom_bar(stat='count', position='dodge') +
  scale_x_continuous(breaks=c(1:11)) +
  xlab('Family Size') +
  ylab("Count") +
  scale_fill_discrete(name = "Survived") + 
  ggtitle("Family Size vs Survived")
```

```{r}
ggplot(complete_df, aes(Age, fill = factor(Survived))) + 
  geom_histogram() + 
  facet_grid(.~Sex)
```

```{r}
ggplot(complete_df, aes(x = Pclass, fill = factor(Survived))) +
  geom_bar(stat='count', position='dodge') +
  xlab('class') +
  ylab("Count") +
  scale_fill_discrete(name = "Survived") + 
  ggtitle("class vs Survived")
```

```{r}
#graph title
ggplot(complete_df, aes(Title,fill = factor(Survived))) +
  geom_bar(stat = "count")+
  xlab('Title') +
  ylab("Count") +
  scale_fill_discrete(name = " Survived") + 
  ggtitle("Title vs Survived")
```
```{r}
#Survived by age
ggplot(complete_df, aes(Age,fill = factor(Survived))) +
  geom_histogram(aes(y=..count..)) +
  xlab('Age') +
  ylab("Density") +
  scale_fill_discrete(name = " Survived") + 
  ggtitle("Survived by Age")
```



## 4. Machine Learning Model
```{r}
complete_df<-complete_df|>
  mutate_at(c("Pclass","Sex","Embarked","Title","ScaleFamily","Child","Mother"),as.factor)|>
  select(Survived,Pclass,Sex,Age,SibSp,Parch,Fare,Embarked,Title,ScaleFamily,Child,Mother)
```


### 4.1 Divide data

```{r}
train_index<-sample.int(nrow(complete_df),round(0.8*nrow(complete_df)))
train_df<-complete_df[train_index,]
test_df<-complete_df[-train_index,]
```

### 4.2 Random Forest

```{r}
# Set a random seed
set.seed(754)

# Build the model (note: not all possible variables are used)
rf_model <- randomForest(Survived ~ .,data = train_df,importance=TRUE )
pred_rf<-predict(rf_model,test_df[,-1])
```

remember to plot all ROC in a same plot and move this to the end

```{r}
prob_pred_RF<-predict(rf_model,test_df,type='response')
label<-test_df[,2]
fitpred_RF<- prediction(prob_pred_RF,label)
fitperf_RF = performance(fitpred_RF,"tpr","fpr")
plot(fitperf_RF,col="green",lwd=2,main="ROC Curve")
```

```{r}
confusionMatrix(pred_rf,test_df$Survived)
```

We can show which are the most relevant variables based on Rf model and then see if the same variables are selected even in the other models

```{r}
# type 2 : mean decrease in node impurity
importance(rf_model,type=2)

# type 1 : mean decrease in accuracy
importance(rf_model,type=1)
```


### 4.3 KNN

```{r}
knn_train<-model.matrix(Survived ~.,data = train_df)[,-1]
knn_test<-model.matrix(Survived ~.,data = test_df)[,-1]
acc_test <- numeric()
for(i in 1:30){
    predict <- knn(train=knn_train, test=knn_test, cl=train_df[,1][[1]], k=i, prob=T)
    acc_test[i] <- mean(as.matrix(predict)==test_df[,1])
}
#############have not fix yet
acc <- data.frame(k= seq(1,30), accuracy = acc_test)

```

```{r}
###check this function tomrrow
plot(acc)
```

```{r}
pred_knn<-knn(train=knn_train, test=knn_test, cl=train_df[,1][[1]], k=6)
confusionMatrix(as.factor(pred_knn),as.factor(test_df[,1][[1]]))
```

### 4.4 Neural Network
problem with NN

```{r}
library(neuralnet)


formula <- as.formula("Survived1 ~ .")
nn_data<-as.data.frame(model.matrix(~.,train_df)[,-1])
nn_model <- neuralnet(
  Survived1 ~ .,
  data = nn_data,
  hidden = c(8, 2), # two hidden layers with 4 and 2 neurons respectively
  threshold = 0.01, 
  act.fct = "logistic" 
)
# Make predictions on the test data
nn_pred <- predict(nn_model,as.data.frame(model.matrix(~.,train_df)[,-1]))

# Convert the predicted probabilities into binary classification
nn_pred_class <- ifelse(nn_pred$net.result > 0.5, 1, 0)

confusionMatrix(as.factor(nn_pred_class), as.factor(test_df$Survived))
```

<<<<<<< HEAD
things need to be done: Write a good story, using NN, Lasso_logistic and use PCA to reduce the dimention the best method in 
origional data.
=======
things need to be done: Write a good story, using NN, Lasso_logistic and use PCA to reduce the dimension 


### 4.5a Ridge regression

```{r}
library(dplyr)
library(glmnet)

```

```{r}
# Cross Validation for Ridge Regression
set.seed(200)
cv.out <- cv.glmnet(knn_train, train_df[,1][[1]], family="binomial",alpha = 0) 
bestlam <- cv.out$lambda.min
ridge_model <- glmnet(knn_train, train_df[,1][[1]], family="binomial",alpha = 0,lambda =bestlam )
pred_ridge <- predict(ridge_model, knn_test,type="response")
```
```{r}
#run Ridge using the best lambda selected from CV
library(glmnet)


```

Maybe check if those predicted coefficients are similar to what we obtain in the other models (random forest etc.)
```{r}


# Compute confusion matrix and statistics
library(caret)
ridge_pred_binary <- ifelse(pred_ridge> 0.5, 1, 0)
actual <- test_df$Survived
confusionMatrix(as.factor(ridge_pred_binary), as.factor(actual))

```


### 4.5b LASSO regression
```{r}
library(glmnet)
lasso_model <- glmnet(knn_train, as.numeric(train_df[,1][[1]]), alpha = 1)
par(mfrow=c(1,2))
plot(lasso_model)
plot(lasso_model, xvar="lambda")
```
Small L1 Norm -> lot of regularization.

```{r}
#Find best lambda through CV
set.seed(200)
cv.out <- cv.glmnet(knn_train, train_df[,1][[1]],family="binomial", alpha = 1)  
plot(cv.out)
```
```{r}
bestlam <- cv.out$lambda.min
lasso_model <- glmnet(knn_train, as.numeric(train_df[,1][[1]]), family = "binomial",alpha = 1, lambda = bestlam )  
```

```{r}
#Prediction using Lasso
lasso_pred <- predict(lasso_model, newx = knn_test,type="response")

# Compute confusion matrix and statistics
library(caret)
lasso_pred_binary <- ifelse(lasso_pred > 0.5, 1,0)
actual <- test_df$Survived
confusionMatrix(as.factor(lasso_pred_binary), as.factor(actual))

```

By checking the accuracy rates of Rf, KNN, Ridge and LASSO, it is clear that RF has more predictive power

```{r}
# Plot the ROC curves LASSO & Ridge
library(ROCR)

lasso_pred_obj <- prediction(lasso_pred, test_df$Survived)
lasso_perf_obj <- performance(lasso_pred_obj, "tpr", "fpr")

ridge_pred_obj <- prediction(pred_ridge, test_df$Survived)
ridge_perf_obj <- performance(ridge_pred_obj, "tpr", "fpr")

plot(lasso_perf_obj, main = "ROC Curve for Lasso and Ridge Models", col = "blue")
plot(ridge_perf_obj, add = TRUE, col = "red")
legend("bottomright", legend = c("Lasso", "Ridge"), col = c("blue", "red"), lwd = 2)

```
##5 PCA

```{r}
x<-complete_df|>
  select(Survived,Pclass, Sex, Age, SibSp, Parch,Fare, Embarked, Title, ScaleFamily, Child, Mother)|>
  mutate_at(c("Survived","Child","Mother"),as.factor)
x<-model.matrix(Survived~.,data=x)
x<-scale(x[,-1])
pca_compo<-prcomp(x)
summary(pca_compo)
plot(pca_compo)
```
too further analysis the contribution of different varaibles to PC1 and PC2
```{r}
pca<-x %*% pca_compo$rotation
train_df_logit<-as.data.frame(cbind(complete_df[train_index,2][[1]],pca[train_index,]))
logit_model<-glm(as.factor(V1)~.,train_df_logit,family=binomial())
pred_logipca<-predict(logit_model,newdata =as.data.frame(pca[-train_index,]),type = "response")
confusionMatrix(as.factor(as.numeric(pred_logipca>0.5)),as.factor(actual))
```















