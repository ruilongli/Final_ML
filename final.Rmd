---
title: "final"
author: "Tom"
date: "2023-04-01"
output: html_document
---

# Using machine learning technique to analysis Titanic database

## 1. Introduction

The Titanic disaster is one of the most catastrophic maritime incidents in history. On her maiden voyage, the supposedly "unsinkable" RMS Titanic collided with an iceberg on April 15, 1912, resulting in the death of 1502 out of 2224 passengers and crew due to insufficient lifeboats.

However, it is evident that certain groups of individuals had a higher chance of surviving than others, irrespective of luck. As a result, we have embarked on a machine learning project that aims to answer the question of which types of passengers were more likely to survive. This will be achieved by analyzing a range of passenger data, including their names, ages, genders, socio-economic classes, and other relevant factors.

The report will be organized as follows: we first discuss the initial steps taken, including data cleaning, feature engineering, and splitting the dataset into training and testing sets. Next, we perform exploratory data analysis to examine our prior beliefs about the correlation between various features and the target variable (Survived). Finally, we employ various machine learning techniques to predict the likelihood of survival for passengers based on different covariates, such as class and gender. By comparing the accuracy rates of these models, we identify the ones that are most effective at predicting survival rates.

### 1.1 The database

```{r}
# Load packages
library(readr)
library(ggplot2) # visualization
library(dplyr) # data manipulation
library(randomForest) # classification algorithm
library(mice) # imputation
library(caret)
library(Amelia) # Missing Data: Missings Map
library(ROCR) # Prediction: ROC Curve
library(class)
```

##1 Data importing 

```{r message=FALSE, warning=FALSE, paged.print=FALSE}
complete_df<-read_csv("train.csv")
#test_df<-read_csv("test.csv")
#complete_df<- bind_rows(train_df, test_df) # bind training & test data
```

```{r}
summary(complete_df)
```

There are 891 observations including 18 features in total in our sample. The detailed explanation for each variable is:

| Variable Name | Description                       |
|---------------|-----------------------------------|
| PassengerId   | Passenger's ID                    |
| Survived      | Survived (1) or died (0)          |
| Pclass        | Passenger's class                 |
| Name          | Passenger's name                  |
| Sex           | Passenger's sex                   |
| Age           | Passenger's age                   |
| SibSp         | Number of siblings/spouses aboard |
| Parch         | Number of parents/children aboard |
| Ticket        | Ticket number                     |
| Fare          | Fare                              |
| Cabin         | Cabin                             |
| Embarked      | Port of embarkation               |
| SizeFamily    | Passenger's family size if any    |
| ScaleFamily   | Family scale (small,large,single) |
| Child         | Child (1) or otherwise (0)        |
| Mother        | Mother (1) or not (0)             |



## 2. Data prepossessing

Throughout the study we will try to confirm or give new insights on the following prior beliefs:

1.  There might be negative correlation between survive and age

2.  there can have positive relationship between survive and family size as family members are more likely to help each other

3.  Men are more likely to survive as they are physically stronger

4.  People in different class will have different chance for survive


However, before starting diving into data analysis, we must standardise some of the variables and deal with missing values. The next two sections will deal with Feauture engeneering and Missing values

### 2.1 Feature engeneering
We first manipulate the 'complete_df' data frame by creating new variables. Specifically we are performing the following operations:
- extracting the title from the variable Name, and creating the new variable 'Title'
- extracting the surname from the variable Name, and creating the new variable 'Surname'
- creating a new variable called 'SizeFamily'
- creating a new variable called ScaleFamily by categorizing SizeFamily into "Single", "small", or "large" based on the number of family members
- creating a new variable called Family by concatenating Surname and SizeFamily

```{r}
rare_title <- c('Dona', 'Lady', 'the Countess','Capt', 'Col', 'Don', 
                'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer')
complete_df<-complete_df|>
  mutate(Title=gsub('(.*, )|(\\..*)', '',Name))|># get title from name.
  #change some non-standard or rare title
  mutate(Title=case_when(Title %in% c("Mlle","MS")~"Miss",
                         Title=="Mme"~"Mrs",
                         Title %in% rare_title ~ "RareTitle",
                         T~Title))|>
  mutate(Surname=sapply(Name,  function(x) strsplit(x, split = '[,.]')[[1]][1]))|>#create the feature of surname
  mutate(SizeFamily=SibSp+Parch+1)|>#family size continuous
  mutate(ScaleFamily=case_when(SizeFamily==1~"Single",
                               SizeFamily>1&SizeFamily<5~"small",
                               SizeFamily>4~"large"))|>#family size discrete
  mutate(Family=paste(Surname,SizeFamily,sep="_"))

```

```{r}
# SHOULD WE INCLUDE THIS PLOT IN THE Exploratory Data Analysis ?
plot(factor(Survived) ~ as.factor(ScaleFamily), data=complete_df)
```

### 2.2 Missing Values

One of the main tasks in data cleaning is dealing with missing values: the graph below counts for each variables how many missing values there are in our sample (891 observations). We can easily verify that for most of the variables there are no missing values but for Cabin, Age, Embarked, there are missing values that need to be addressed during data cleaning.

```{r}
missmap(complete_df, main="Titanic Data - Missings Map",
        col=c("yellow", "black"), legend=FALSE)
```

Regarding the 'Embarked' variable, we have identified two missing values in our sample. To deal with this, we will replace the missing values with the mode of the 'Embarked' variable.

```{r}
complete_df<-complete_df|>
  mutate(Embarked=case_when(is.na(Embarked)~"C",
                            T~Embarked))
```

For the variable Age instead, we have many more missing values which leads us to use another method.
The method used for imputing the missing values in the Age variable is a predictive imputation based on a random forest model. This method estimates the missing values by filling them in with values based on the available information in the other variables. The model is trained on the available data with complete information, and then used to predict the missing values. The random forest algorithm is chosen because it can exclude certain less useful variables for imputation and can handle non-linear relationships between variables.

In the first block, the imputation is performed, and the complete output is saved as "output". In the second block we check the two histograms to visually compare the distribution of the original data and the imputed data. The two distributions looks pretty similar suggesting that the imputation method has done a good job in preserving the distribution of the original data


```{r}
# Make variables factors into factors
factor_vars <- c('PassengerId','Pclass','Sex','Embarked',
                 'Title','Surname','ScaleFamily')
complete_df[factor_vars] <- lapply(complete_df[factor_vars], function(x) as.factor(x))
# Set a random seed
set.seed(123)
# Perform mice imputation, excluding certain less-than-useful variables:
mdl <- mice(complete_df[, !names(complete_df) %in% c('PassengerId','Name','Ticket','Cabin','Survived',"Family")], method='rf') 
```

```{r}
# Save the complete output 
age_mice <- complete(mdl)
par(mfrow=c(1,2))
hist(complete_df$Age, freq=F, main='Original Data', 
  col='blue', ylim=c(0,0.04))
hist(age_mice$Age, freq=F, main='Output', 
  col='lightblue', ylim=c(0,0.04))
```

```{r}
complete_df$Age<-age_mice$Age
```

### 2.3 Feature engineering on age
We graphed our initial assumptions about how survival rates may be linked to various covariates, such as age, gender and passengers' class.

We first start by checking the correlation between age and gender on survival rate.
```{r}
complete_df<-complete_df|>
  mutate(Child=case_when(Age<18~1,
                         Age>17~0))|>
  mutate(Mother=case_when(Sex=="female"&Parch>0&Age>18&Title!="Miss"~1,
                          T~0))
```

### 2.3 Exploratory Data Analysis
Upon plotting the survival rate against family size, we observe that there is no clear linear relationship between the two variables: indeed, for small family size (1-4 members) the ratio of those who survived, ranges between 0.30 and 0.7, for medium family size (5-7 members), the ratio drops below 0.3, whereas for large family size (>8) the ratio drops to 0. Hence we can notice that there are high fluctuations not only between the different family size (small, medium, large) but also within each of the family size groups.

```{r}
ggplot(complete_df, aes(x = SizeFamily, fill = factor(Survived))) +
  geom_bar(position = "fill") +
  scale_x_continuous(breaks=c(1:11)) +
  xlab('Family Size') +
  ylab("Proportion") +
  scale_fill_discrete(name = "Survived") + 
  ggtitle("Family Size vs Survived") 

```
In the next two graphs we analyse the relationship between survival rate and age. We first plot the density functions of the two groups (Survived binary variable), and we can notice a fatter right tail (age above 40) for the density function of those passengers who did not survive to the catastrophe, indicating a potential negative relationship between age and survival rate. 
The second graph instead analyzes still the same relationship but this time by gender: a really interesting insight is that for female passengers the two density distributions tend to overlap, meaning that regardless of the age females were more likely to survive. This insight is perhaps consistent with the priority in evacuation; indeed we can notice that the density distributions for male passengers is highly volatile, mainly due to two opposite forces: physical strength gives an advantage to male but during the evacuation process, women and children were given priority to board the lifeboats, leaving male passengers to board last.

```{r}
#Survived by age
ggplot(complete_df, aes(Age,fill = factor(Survived))) +
  geom_histogram(aes(y=..count..)) +
  xlab('Age') +
  ylab("Density") +
  scale_fill_discrete(name = " Survived") + 
  ggtitle("Survived by Age")
```

```{r}
ggplot(complete_df, aes(Age, fill = factor(Survived))) + 
  geom_histogram() + 
  facet_grid(.~Sex)
```
Next we plot the relationship between passenger's class and survival rate, and we can verify that the first class had more chances to survive compared to the third one: the impact of class is indicative of the imbalanced socioeconomichierarchy during 1912.

```{r}
ggplot(complete_df, aes(x = Pclass, fill = factor(Survived))) +
  geom_bar(stat='count', position='dodge') +
  xlab('class') +
  ylab("Count") +
  scale_fill_discrete(name = "Survived") + 
  ggtitle("class vs Survived")
```

```{r}
#graph title
ggplot(complete_df, aes(Title,fill = factor(Survived))) +
  geom_bar(stat = "count")+
  xlab('Title') +
  ylab("Count") +
  scale_fill_discrete(name = " Survived") + 
  ggtitle("Title vs Survived")
```


## 4. Machine Learning Model
```{r}
complete_df<-complete_df|>
  mutate_at(c("Pclass","Sex","Embarked","Title","ScaleFamily","Child","Mother"),as.factor)|>
  select(Survived,Pclass,Sex,Age,SibSp,Parch,Fare,Embarked,Title,ScaleFamily,Child,Mother)
```


Our study aims at predicting the survival rates of Titanic passengers by identifying the variables that have the greatest impact on survival. To achieve this, we begin by dividing the data into two datasets: 80% of the sample will be used for training, and the remaining 20% for testing purposes.

### 4.1 Divide data
```{r}
train_index<-sample.int(nrow(complete_df),round(0.8*nrow(complete_df)))
train_df<-complete_df[train_index,]
test_df<-complete_df[-train_index,]
```

We start by analyzing Random Forest model first: we run the rf_model and store the predicted values. We then plot the ROC curve and the confusion matrix. In the last part of our rf_model we calculate the MDA (Mean Decrease Accuracy) for each variable: the higher the MDA score for a variable, the more important it is in predicting the target variable. In  our specific case as we can see from the last plot, we can state that the social status and the age were the key determinants for the survival.

### 4.2 Random Forest


```{r}
# Set a random seed
set.seed(754)

# Build the model (note: not all possible variables are used)
rf_model <- randomForest(Survived ~ .,data = train_df,importance=TRUE )
pred_rf<-predict(rf_model,test_df[,-1])
```


```{r}
prob_pred_RF<-predict(rf_model,test_df,type='response')
label<-test_df[,1]
fitpred_RF<- prediction(prob_pred_RF>0.5,label)
fitperf_RF = performance(fitpred_RF,"tpr","fpr")
plot(fitperf_RF,col="green",lwd=2,main="ROC Curve (RF)")
```

```{r}
confusionMatrix(as.factor(as.numeric(pred_rf>0.5)),as.factor(test_df$Survived))
```

```{r}
# type 1 : mean decrease in accuracy
importance(rf_model,type=1)
```
```{r}
var_imp <- importance(rf_model, type = 1)
var_imp_df <- data.frame(variable = row.names(var_imp), importance = var_imp[,"%IncMSE"])
var_imp_df <- var_imp_df[order(var_imp_df$importance, decreasing = TRUE),]
ggplot(var_imp_df, aes(x = reorder(variable, importance), y = importance)) + 
   geom_bar(stat = "identity", fill = "#FFB6C1") +
  coord_flip() +
  labs(title = "Variable Importance based on %IncMSE", x = "Variable", y = "Importance")

```


### 4.3 KNN

```{r}


train_matrix<-model.matrix(Survived ~.,data = train_df)[,-1]
test_matrix<-model.matrix(Survived ~.,data = test_df)[,-1]
acc_test <- numeric()
for(i in 1:30){
    predict <- knn(train=train_matrix, test=test_matrix, cl=train_df[,1][[1]], k=i, prob=T)
    acc_test[i] <- mean(as.matrix(predict)==test_df[,1])
}
#############have not fix yet
acc <- data.frame(k= seq(1,30), accuracy = acc_test)

```

```{r}
###check this function tomrrow
plot(acc)
```

```{r}
pred_knn<-knn(train=knn_train, test=knn_test, cl=train_df[,1][[1]], k=14)
confusionMatrix(as.factor(pred_knn),as.factor(test_df[,1][[1]]))
```

### 4.4 Neural Network
problem with NN

```{r}
library(nnet)
library(caret)

# Define the model architecture
NN_model <- nnet(Survived ~ Pclass + Sex + Age + SibSp + Parch + Fare + Embarked + Title + ScaleFamily + Child + Mother,
              data = train_df,
              size = 5,  # Number of hidden units
              decay = 1e-5,  # Weight decay parameter for regularization
              maxit = 1000)  # Maximum number of iterations

# Make predictions on the test data
pred <- predict(NN_model, newdata = test_df)

# Convert the predicted probabilities to binary predictions
pred_binary <- ifelse(pred > 0.5, 1, 0)

# Create a confusion matrix
confusionMatrix(data = factor(pred_binary, levels = c(0, 1)), 
                reference = factor(test_df$Survived, levels = c(0, 1)))

```

Hyperparameter tuning (change the number of hidden units)
```{r}
library(nnet)
library(caret)

set.seed(123)
# Define the tuning grid
tune_grid <- expand.grid(size = c(2, 3, 4, 5, 10), decay = c(1e-5, 1e-4, 1e-3))


# Define the model formula
NN_tuned <- as.formula("Survived ~ Pclass + Sex + Age + SibSp + Parch + Fare + Embarked + Title + ScaleFamily + Child + Mother")

# Set up the train control
train_control <- trainControl(method = "cv", number = 5)  #number of folds in the CV

# Train the model using cross-validation
tuned_model <- train(
  NN_tuned,
  data = train_df,
  method = "nnet",
  tuneGrid = tune_grid,
  trControl = train_control,
  maxit = 1000,
  linout = TRUE,
  trace = FALSE)

# Print the results
tuned_model

```



### 4.5a Ridge regression

```{r}
library(dplyr)
library(glmnet)

```

```{r}
# Cross Validation for Ridge Regression
set.seed(200)
cv.out <- cv.glmnet(train_matrix, train_df[,1][[1]], family="binomial",alpha = 0) 
bestlam <- cv.out$lambda.min
ridge_model <- glmnet(knn_train, train_df[,1][[1]], family="binomial",alpha = 0,lambda =bestlam )
pred_ridge <- predict(ridge_model, knn_test,type="response")
```
```{r}
#run Ridge using the best lambda selected from CV
library(glmnet)


```


```{r}


# Compute confusion matrix and statistics
library(caret)
ridge_pred_binary <- ifelse(pred_ridge> 0.5, 1, 0)
confusionMatrix(as.factor(ridge_pred_binary), as.factor(test_df$Survived))

```


### 4.5b LASSO regression
```{r}
library(glmnet)
lasso_model <- glmnet(train_matrix, train_df$Survived, alpha = 1)
par(mfrow=c(1,2))
plot(lasso_model)
plot(lasso_model, xvar="lambda")
```
Small L1 Norm -> lot of regularization.

```{r}
#Find best lambda through CV
set.seed(200)
cv.out <- cv.glmnet(knn_train, train_df$Survived,family="binomial", alpha = 1)  
plot(cv.out)
```
```{r}
bestlam <- cv.out$lambda.min
lasso_model <- glmnet(knn_train, train_df$Survived, family = "binomial",alpha = 1, lambda = bestlam )  
```

```{r}
#Prediction using Lasso
lasso_pred <- predict(lasso_model, newx = knn_test,type="response")

# Compute confusion matrix and statistics
library(caret)
lasso_pred_binary <- ifelse(lasso_pred > 0.5, 1,0)
actual <- test_df$Survived
confusionMatrix(as.factor(lasso_pred_binary), as.factor(actual))

```

By checking the accuracy rates of Rf, KNN, Ridge and LASSO, it is clear that RF has more predictive power

```{r}
# Plot the ROC curves LASSO & Ridge
library(ROCR)
###there are bugs
lasso_pred_obj <- prediction(lasso_pred, test_df$Survived)
lasso_perf_obj <- performance(lasso_pred_obj, "tpr", "fpr")

ridge_pred_obj <- prediction(pred_ridge, test_df$Survived)
ridge_perf_obj <- performance(ridge_pred_obj, "tpr", "fpr")

plot(lasso_perf_obj, main = "ROC Curve for Lasso and Ridge Models", col = "blue")
plot(ridge_perf_obj, add = TRUE, col = "red")
legend("bottomright", legend = c("Lasso", "Ridge"), col = c("blue", "red"), lwd = 2)

```
##5 PCA

```{r}

complete_matrix<-model.matrix(Survived~.,data=complete_df)
complete_matrix<-scale(complete_matrix[,-1])
pca_compo<-prcomp(complete_matrix)
summary(pca_compo)
plot(pca_compo)
```
too further analysis the contribution of different varaibles to PC1 and PC2
```{r}
pca<-complete_matrix %*% pca_compo$rotation
train_df_logit<-as.data.frame(cbind(train_df$Survived,pca[train_index,]))
logit_model<-glm(V1~.,train_df_logit,family=binomial())
pred_logipca<-predict(logit_model,newdata =as.data.frame(pca[-train_index,]),type = "response")
confusionMatrix(as.factor(as.numeric(pred_logipca>0.5)),as.factor(actual))
```















